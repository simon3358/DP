{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import encode_data_get_embeddings, create_emoji_sentiment\n",
    "import model as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacitanie dat a embedingov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEPOTREBNE\n",
    "\n",
    "# ziskanie celeho datasetu z 3 zdrojov\n",
    "\n",
    "# e2v_tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data.csv')\n",
    "# semeval = pd.read_csv('D:/Downloads/DP/data/semeval_data.csv')\n",
    "# sample = pd.read_csv('D:/Downloads/DP/data/twitter_sample.csv', sep=',', engine='python')\n",
    "\n",
    "# semeval['Label'] = semeval['Label'].apply(lambda x: 'Positive' if x == 'positive' else ('Neutral' if x =='neutral' else 'Negative'))\n",
    "# sample['Label'] = sample['Label'].apply(lambda x: 'Positive' if x == 0 else ('Neutral' if x == 0 else 'Negative'))\n",
    "\n",
    "# tweets = pd.concat([old_tweets, semeval, sample], ignore_index=True)\n",
    "\n",
    "# tweets.to_csv('D:/Downloads/DP/data/twitter_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data.csv')\n",
    "# tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data_emoji.csv')\n",
    "\n",
    "# tweets = pd.read_csv('D:/Downloads/DP/data/emocontext.csv')\n",
    "# tweets = pd.read_csv('D:/Downloads/DP/data/emocontext_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 300\n",
      "\n",
      "1661 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v = open('D:\\Downloads\\DP\\word2vec300_en.vec', encoding=\"utf8\")\n",
    "w2v_dim = w2v.readline()\n",
    "print(w2v_dim)\n",
    "\n",
    "e2v = open('D:\\Downloads\\DP\\emoji2vec300.txt', encoding=\"utf8\")\n",
    "e2v_dim = e2v.readline()\n",
    "print(e2v_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, None)\n",
    "train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, e2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51679"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12920"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcie - Neuronove siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "- e2v data: 46% (with/out e2v)\n",
    "- emoji data: 25% (with/out e2v)\n",
    "- sample data: 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3679/3679 [==============================] - 87s 24ms/step - loss: 0.1552 - acc: 0.1649 - val_loss: 0.1269 - val_acc: 0.1637\n",
      "Epoch 2/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1453 - acc: 0.1624 - val_loss: 0.1179 - val_acc: 0.1631\n",
      "Epoch 3/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1310 - acc: 0.1613 - val_loss: 0.1196 - val_acc: 0.1630\n",
      "Epoch 4/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1287 - acc: 0.1612 - val_loss: 0.1182 - val_acc: 0.1630\n",
      "Epoch 5/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1291 - acc: 0.1612 - val_loss: 0.1175 - val_acc: 0.1630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b12d75d390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10143047571182251, acc: 0.1616787612438202\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselineDrop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1292/1292 [==============================] - 35s 27ms/step - loss: 0.1600 - acc: 0.4608 - val_loss: 0.1721 - val_acc: 0.4550\n",
      "Epoch 2/5\n",
      "1292/1292 [==============================] - 35s 27ms/step - loss: 0.1503 - acc: 0.4612 - val_loss: 0.1794 - val_acc: 0.4550\n",
      "Epoch 3/5\n",
      "1292/1292 [==============================] - 36s 28ms/step - loss: 0.1530 - acc: 0.4610 - val_loss: 0.1714 - val_acc: 0.4569\n",
      "Epoch 4/5\n",
      "1292/1292 [==============================] - 40s 31ms/step - loss: 0.1960 - acc: 0.4572 - val_loss: 0.3097 - val_acc: 0.4471\n",
      "Epoch 5/5\n",
      "1292/1292 [==============================] - 41s 31ms/step - loss: 0.2088 - acc: 0.4567 - val_loss: 0.1994 - val_acc: 0.4549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b9ee9a588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineDropModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18892277777194977, acc: 0.46122291684150696\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 13s 115ms/step - loss: -1.0244 - acc: 0.3762 - val_loss: -1.5107 - val_acc: 0.3341\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 11s 98ms/step - loss: -1.4884 - acc: 0.4302 - val_loss: -1.5820 - val_acc: 0.4598\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 11s 100ms/step - loss: -1.6164 - acc: 0.3240 - val_loss: -1.6535 - val_acc: 0.3059\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 10s 95ms/step - loss: -1.2929 - acc: 0.3465 - val_loss: -1.1082 - val_acc: 0.4153\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 11s 100ms/step - loss: -1.4010 - acc: 0.3545 - val_loss: -1.5625 - val_acc: 0.2516\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 11s 100ms/step - loss: -1.2555 - acc: 0.2757 - val_loss: -1.3604 - val_acc: 0.2708\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 11s 103ms/step - loss: -1.3701 - acc: 0.2894 - val_loss: -1.6187 - val_acc: 0.2590\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 11s 99ms/step - loss: -1.5024 - acc: 0.2810 - val_loss: -1.5444 - val_acc: 0.2541\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 10s 96ms/step - loss: -1.5518 - acc: 0.2792 - val_loss: -1.6843 - val_acc: 0.2563\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 10s 95ms/step - loss: -1.6163 - acc: 0.2811 - val_loss: -1.5885 - val_acc: 0.2684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff484414e0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.LstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1.4610261917114258, acc: 0.2863207757472992\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLstm model\n",
    "- zatial najlepsie\n",
    "- epoch 5, batch 64, bilstm(256): 47.65%\n",
    "- epoch 5, batch 64, bilstm(128): 46.64%\n",
    "- epoch 15, batch 64, bilstm(128): 51.32%\n",
    "- epoch 10, batch 32, bilstm(256): 51.83%\n",
    "- epoch 30, batch 64, bilstm(256): 51.80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1292/1292 [==============================] - 683s 528ms/step - loss: -0.0644 - acc: 0.4628 - val_loss: -1.2072 - val_acc: 0.4649\n",
      "Epoch 2/10\n",
      "1292/1292 [==============================] - 552s 427ms/step - loss: -1.8135 - acc: 0.4689 - val_loss: -0.8475 - val_acc: 0.4732\n",
      "Epoch 3/10\n",
      "1292/1292 [==============================] - 658s 509ms/step - loss: -3.6141 - acc: 0.4753 - val_loss: -12.6053 - val_acc: 0.4816\n",
      "Epoch 4/10\n",
      "1292/1292 [==============================] - 554s 429ms/step - loss: -7.4917 - acc: 0.4725 - val_loss: -7.9945 - val_acc: 0.4803\n",
      "Epoch 5/10\n",
      "1292/1292 [==============================] - 550s 426ms/step - loss: -20.6729 - acc: 0.4747 - val_loss: -14.5436 - val_acc: 0.4755\n",
      "Epoch 6/10\n",
      "1292/1292 [==============================] - 551s 426ms/step - loss: -38.8993 - acc: 0.4778 - val_loss: -63.7959 - val_acc: 0.4872\n",
      "Epoch 7/10\n",
      "1292/1292 [==============================] - 564s 437ms/step - loss: -80.4777 - acc: 0.4811 - val_loss: -52.0948 - val_acc: 0.4648\n",
      "Epoch 8/10\n",
      "1292/1292 [==============================] - 660s 511ms/step - loss: -43.6272 - acc: 0.4640 - val_loss: -81.3779 - val_acc: 0.4726\n",
      "Epoch 9/10\n",
      "1292/1292 [==============================] - 553s 428ms/step - loss: -89.1289 - acc: 0.4762 - val_loss: -125.0767 - val_acc: 0.4824\n",
      "Epoch 10/10\n",
      "1292/1292 [==============================] - 557s 431ms/step - loss: -147.5846 - acc: 0.4842 - val_loss: -175.9423 - val_acc: 0.4826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b2d4bf240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -170.59181213378906, acc: 0.4808049499988556\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1292/1292 [==============================] - 554s 429ms/step - loss: 0.0798 - acc: 0.4610 - val_loss: 0.5632 - val_acc: 0.4553\n",
      "Epoch 2/10\n",
      "1292/1292 [==============================] - 545s 421ms/step - loss: -0.2002 - acc: 0.4619 - val_loss: 0.0506 - val_acc: 0.4574\n",
      "Epoch 3/10\n",
      "1292/1292 [==============================] - 564s 437ms/step - loss: -0.0424 - acc: 0.4650 - val_loss: -0.2589 - val_acc: 0.4577\n",
      "Epoch 4/10\n",
      "1292/1292 [==============================] - 583s 451ms/step - loss: -0.2362 - acc: 0.4639 - val_loss: -0.1299 - val_acc: 0.4602\n",
      "Epoch 5/10\n",
      "1292/1292 [==============================] - 572s 443ms/step - loss: -0.8435 - acc: 0.4725 - val_loss: -1.1468 - val_acc: 0.5018\n",
      "Epoch 6/10\n",
      "1292/1292 [==============================] - 569s 440ms/step - loss: -1.1712 - acc: 0.4839 - val_loss: -1.3310 - val_acc: 0.4689\n",
      "Epoch 7/10\n",
      "1292/1292 [==============================] - 540s 418ms/step - loss: -0.8657 - acc: 0.4749 - val_loss: -1.2684 - val_acc: 0.4702\n",
      "Epoch 8/10\n",
      "1292/1292 [==============================] - 531s 411ms/step - loss: -1.3547 - acc: 0.4917 - val_loss: -0.9495 - val_acc: 0.4938\n",
      "Epoch 9/10\n",
      "1292/1292 [==============================] - 585s 453ms/step - loss: -1.4537 - acc: 0.5080 - val_loss: -1.5250 - val_acc: 0.5150\n",
      "Epoch 10/10\n",
      "1292/1292 [==============================] - 555s 429ms/step - loss: -1.4946 - acc: 0.5108 - val_loss: -1.4480 - val_acc: 0.5141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29ba122e4a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1.3393548727035522, acc: 0.5148705244064331\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1292/1292 [==============================] - 89s 69ms/step - loss: -988483.5000 - acc: 0.4483 - val_loss: -4403449.0000 - val_acc: 0.4309\n",
      "Epoch 2/5\n",
      "1292/1292 [==============================] - 87s 67ms/step - loss: -27949140.0000 - acc: 0.4437 - val_loss: -57549448.0000 - val_acc: 0.4421\n",
      "Epoch 3/5\n",
      "1292/1292 [==============================] - 87s 67ms/step - loss: -149946816.0000 - acc: 0.4436 - val_loss: -222597328.0000 - val_acc: 0.4482\n",
      "Epoch 4/5\n",
      "1292/1292 [==============================] - 95s 74ms/step - loss: -460484768.0000 - acc: 0.4442 - val_loss: -571984832.0000 - val_acc: 0.4502\n",
      "Epoch 5/5\n",
      "1292/1292 [==============================] - 105s 81ms/step - loss: -1016310080.0000 - acc: 0.4449 - val_loss: -1172016640.0000 - val_acc: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29bb4353470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.ConvModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1159315328.0, acc: 0.45410215854644775\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101147, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12228, 300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tw_tok = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "x = np.array((tweets['Text']).apply(lambda x: ' '.join([w for w in tw_tok.tokenize(x)])))\n",
    "\n",
    "# One-hot encoding labelu\n",
    "y = np.array(tweets['Label'].apply(lambda x: 2 if x == 'Positive' else (1 if x =='Neutral' else 0)))\n",
    "#     y = np.array(tweets['Label'].apply(lambda x: 1 if x == 'Positive' else 0))\n",
    "\n",
    "tweet_count = len(tweets)\n",
    "limit = int(0.8 * tweet_count)\n",
    "\n",
    "train_x = x[:limit]\n",
    "train_y = y[:limit]\n",
    "test_x = x[limit:]\n",
    "test_y = y[limit:]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "train_x = tokenizer.texts_to_sequences(train_x)\n",
    "test_x = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59991"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikacia do 2 tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "646/646 [==============================] - 600s 929ms/step - loss: 0.5804 - acc: 0.7224 - val_loss: 0.5911 - val_acc: 0.7197\n",
      "Epoch 2/15\n",
      "646/646 [==============================] - 584s 903ms/step - loss: 0.5721 - acc: 0.7301 - val_loss: 0.5305 - val_acc: 0.7533\n",
      "Epoch 3/15\n",
      "646/646 [==============================] - 557s 862ms/step - loss: 0.5083 - acc: 0.7679 - val_loss: 0.4926 - val_acc: 0.7774\n",
      "Epoch 4/15\n",
      "646/646 [==============================] - 613s 949ms/step - loss: 0.4787 - acc: 0.7866 - val_loss: 0.4837 - val_acc: 0.7819\n",
      "Epoch 5/15\n",
      "646/646 [==============================] - 625s 968ms/step - loss: 0.4696 - acc: 0.7918 - val_loss: 0.4764 - val_acc: 0.7853\n",
      "Epoch 6/15\n",
      "646/646 [==============================] - 608s 942ms/step - loss: 0.4605 - acc: 0.7960 - val_loss: 0.4684 - val_acc: 0.7930\n",
      "Epoch 7/15\n",
      "646/646 [==============================] - 614s 950ms/step - loss: 0.4533 - acc: 0.8008 - val_loss: 0.4660 - val_acc: 0.7937\n",
      "Epoch 8/15\n",
      "646/646 [==============================] - 621s 961ms/step - loss: 0.4467 - acc: 0.8041 - val_loss: 0.4763 - val_acc: 0.7881\n",
      "Epoch 9/15\n",
      "646/646 [==============================] - 603s 933ms/step - loss: 0.4391 - acc: 0.8074 - val_loss: 0.4649 - val_acc: 0.7956\n",
      "Epoch 10/15\n",
      "646/646 [==============================] - 608s 941ms/step - loss: 0.4309 - acc: 0.8109 - val_loss: 0.4594 - val_acc: 0.7975\n",
      "Epoch 11/15\n",
      "646/646 [==============================] - 628s 972ms/step - loss: 0.4231 - acc: 0.8155 - val_loss: 0.4666 - val_acc: 0.7975\n",
      "Epoch 12/15\n",
      "646/646 [==============================] - 611s 946ms/step - loss: 0.4126 - acc: 0.8205 - val_loss: 0.4670 - val_acc: 0.7993\n",
      "Epoch 13/15\n",
      "646/646 [==============================] - 622s 963ms/step - loss: 0.4005 - acc: 0.8262 - val_loss: 0.4699 - val_acc: 0.7945\n",
      "Epoch 14/15\n",
      "646/646 [==============================] - 625s 967ms/step - loss: 0.3874 - acc: 0.8326 - val_loss: 0.4768 - val_acc: 0.7955\n",
      "Epoch 15/15\n",
      "646/646 [==============================] - 639s 988ms/step - loss: 0.3730 - acc: 0.8408 - val_loss: 0.4788 - val_acc: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3ed9dbf60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.49845778942108154, acc: 0.7808824777603149\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
