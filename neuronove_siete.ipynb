{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import encode_data_get_embeddings\n",
    "import model as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacitanie dat a embedingov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ziskanie celeho datasetu z 3 zdrojov\n",
    "\n",
    "# e2v_tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data.csv')\n",
    "# semeval = pd.read_csv('D:/Downloads/DP/data/semeval_data.csv')\n",
    "# sample = pd.read_csv('D:/Downloads/DP/data/twitter_sample.csv', sep=',', engine='python')\n",
    "\n",
    "# semeval['Label'] = semeval['Label'].apply(lambda x: 'Positive' if x == 'positive' else ('Neutral' if x =='neutral' else 'Negative'))\n",
    "# sample['Label'] = sample['Label'].apply(lambda x: 'Positive' if x == 0 else ('Neutral' if x == 0 else 'Negative'))\n",
    "\n",
    "# tweets = pd.concat([old_tweets, semeval, sample], ignore_index=True)\n",
    "\n",
    "# tweets.to_csv('D:/Downloads/DP/data/twitter_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data.csv')\n",
    "\n",
    "tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    4853\n",
       "Negative    3157\n",
       "Neutral     2855\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 300\n",
      "\n",
      "1661 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v = open('D:\\Downloads\\DP\\word2vec300_en.vec', encoding=\"utf8\")\n",
    "w2v_dim = w2v.readline()\n",
    "print(w2v_dim)\n",
    "\n",
    "e2v = open('D:\\Downloads\\DP\\emoji2vec300.txt', encoding=\"utf8\")\n",
    "e2v_dim = e2v.readline()\n",
    "print(e2v_dim)\n",
    "\n",
    "train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcie - Neuronove siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "- e2v data: 46% (with/out e2v)\n",
    "- emoji data: 25% (with/out e2v)\n",
    "- sample data: 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3679/3679 [==============================] - 87s 24ms/step - loss: 0.1552 - acc: 0.1649 - val_loss: 0.1269 - val_acc: 0.1637\n",
      "Epoch 2/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1453 - acc: 0.1624 - val_loss: 0.1179 - val_acc: 0.1631\n",
      "Epoch 3/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1310 - acc: 0.1613 - val_loss: 0.1196 - val_acc: 0.1630\n",
      "Epoch 4/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1287 - acc: 0.1612 - val_loss: 0.1182 - val_acc: 0.1630\n",
      "Epoch 5/5\n",
      "3679/3679 [==============================] - 83s 23ms/step - loss: 0.1291 - acc: 0.1612 - val_loss: 0.1175 - val_acc: 0.1630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b12d75d390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10143047571182251, acc: 0.1616787612438202\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselineDrop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1292/1292 [==============================] - 35s 27ms/step - loss: 0.1600 - acc: 0.4608 - val_loss: 0.1721 - val_acc: 0.4550\n",
      "Epoch 2/5\n",
      "1292/1292 [==============================] - 35s 27ms/step - loss: 0.1503 - acc: 0.4612 - val_loss: 0.1794 - val_acc: 0.4550\n",
      "Epoch 3/5\n",
      "1292/1292 [==============================] - 36s 28ms/step - loss: 0.1530 - acc: 0.4610 - val_loss: 0.1714 - val_acc: 0.4569\n",
      "Epoch 4/5\n",
      "1292/1292 [==============================] - 40s 31ms/step - loss: 0.1960 - acc: 0.4572 - val_loss: 0.3097 - val_acc: 0.4471\n",
      "Epoch 5/5\n",
      "1292/1292 [==============================] - 41s 31ms/step - loss: 0.2088 - acc: 0.4567 - val_loss: 0.1994 - val_acc: 0.4549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b9ee9a588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineDropModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18892277777194977, acc: 0.46122291684150696\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "646/646 [==============================] - 153s 237ms/step - loss: 0.1584 - acc: 0.4606 - val_loss: 0.1953 - val_acc: 0.4612\n",
      "Epoch 2/10\n",
      "646/646 [==============================] - 159s 246ms/step - loss: 0.1548 - acc: 0.4608 - val_loss: 0.1994 - val_acc: 0.4612\n",
      "Epoch 3/10\n",
      "646/646 [==============================] - 178s 275ms/step - loss: 0.1516 - acc: 0.4607 - val_loss: 0.2000 - val_acc: 0.4612\n",
      "Epoch 4/10\n",
      "646/646 [==============================] - 154s 238ms/step - loss: 0.1520 - acc: 0.4607 - val_loss: 0.2015 - val_acc: 0.4612\n",
      "Epoch 5/10\n",
      "646/646 [==============================] - 146s 226ms/step - loss: 0.1553 - acc: 0.4607 - val_loss: 0.2014 - val_acc: 0.4612\n",
      "Epoch 6/10\n",
      "646/646 [==============================] - 146s 226ms/step - loss: 0.1532 - acc: 0.4607 - val_loss: 0.1964 - val_acc: 0.4612\n",
      "Epoch 7/10\n",
      "646/646 [==============================] - 171s 265ms/step - loss: 0.1500 - acc: 0.4607 - val_loss: 0.2127 - val_acc: 0.4612\n",
      "Epoch 8/10\n",
      "646/646 [==============================] - 176s 273ms/step - loss: 0.1538 - acc: 0.4607 - val_loss: 0.1973 - val_acc: 0.4612\n",
      "Epoch 9/10\n",
      "646/646 [==============================] - 145s 225ms/step - loss: 0.1526 - acc: 0.4607 - val_loss: 0.2028 - val_acc: 0.4612\n",
      "Epoch 10/10\n",
      "646/646 [==============================] - 146s 226ms/step - loss: 0.1532 - acc: 0.4607 - val_loss: 0.1953 - val_acc: 0.4612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23726b3a4e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.LstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.153344988822937, acc: 0.45743033289909363\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLstm model\n",
    "- zatial najlepsie\n",
    "- epoch 5, batch 64, bilstm(256): 47.65%\n",
    "- epoch 5, batch 64, bilstm(128): 46.64%\n",
    "- epoch 15, batch 64, bilstm(128): 51.32%\n",
    "- epoch 10, batch 32, bilstm(256): 51.83%\n",
    "- epoch 30, batch 64, bilstm(256): 51.80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1292/1292 [==============================] - 641s 496ms/step - loss: 0.0492 - acc: 0.4642 - val_loss: -0.2311 - val_acc: 0.4561\n",
      "Epoch 2/10\n",
      "1292/1292 [==============================] - 623s 482ms/step - loss: -0.1584 - acc: 0.4643 - val_loss: -0.7739 - val_acc: 0.4575\n",
      "Epoch 3/10\n",
      "1292/1292 [==============================] - 644s 499ms/step - loss: -0.7211 - acc: 0.4861 - val_loss: -1.4996 - val_acc: 0.4900\n",
      "Epoch 4/10\n",
      "1292/1292 [==============================] - 630s 488ms/step - loss: -0.9307 - acc: 0.4881 - val_loss: -1.5085 - val_acc: 0.5014\n",
      "Epoch 5/10\n",
      "1292/1292 [==============================] - 612s 474ms/step - loss: -1.3948 - acc: 0.5033 - val_loss: -1.6503 - val_acc: 0.5112\n",
      "Epoch 6/10\n",
      "1292/1292 [==============================] - 608s 471ms/step - loss: -1.3434 - acc: 0.5059 - val_loss: -1.6544 - val_acc: 0.5023\n",
      "Epoch 7/10\n",
      "1292/1292 [==============================] - 615s 476ms/step - loss: -1.3339 - acc: 0.5045 - val_loss: -1.6761 - val_acc: 0.5033\n",
      "Epoch 8/10\n",
      "1292/1292 [==============================] - 605s 468ms/step - loss: -1.4535 - acc: 0.5052 - val_loss: -1.7568 - val_acc: 0.5092\n",
      "Epoch 9/10\n",
      "1292/1292 [==============================] - 628s 486ms/step - loss: -1.4216 - acc: 0.5078 - val_loss: -1.6958 - val_acc: 0.5114\n",
      "Epoch 10/10\n",
      "1292/1292 [==============================] - 629s 487ms/step - loss: -1.5020 - acc: 0.5180 - val_loss: -1.7392 - val_acc: 0.4994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b85e6e90b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1.514198660850525, acc: 0.509103000164032\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "218/218 [==============================] - 107s 489ms/step - loss: 0.4177 - acc: 0.2653 - val_loss: 0.3573 - val_acc: 0.2684\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 110s 503ms/step - loss: 0.3264 - acc: 0.2669 - val_loss: 0.3145 - val_acc: 0.2700\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 115s 526ms/step - loss: 1.3062 - acc: 0.2618 - val_loss: 0.4127 - val_acc: 0.2634\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 118s 542ms/step - loss: 0.2163 - acc: 0.2666 - val_loss: 0.7264 - val_acc: 0.2693\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 111s 511ms/step - loss: 0.1762 - acc: 0.2662 - val_loss: 0.4238 - val_acc: 0.2729\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 109s 502ms/step - loss: 0.4425 - acc: 0.2622 - val_loss: 0.4423 - val_acc: 0.2634\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 111s 508ms/step - loss: 0.4367 - acc: 0.2601 - val_loss: 0.4127 - val_acc: 0.2637\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 109s 501ms/step - loss: 0.4377 - acc: 0.2602 - val_loss: 0.4374 - val_acc: 0.2634\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 104s 477ms/step - loss: 0.4402 - acc: 0.2602 - val_loss: 0.4224 - val_acc: 0.2643\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 104s 477ms/step - loss: 0.4248 - acc: 0.2604 - val_loss: 0.4253 - val_acc: 0.2643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b7916144a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.46410101652145386, acc: 0.2723711431026459\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1292/1292 [==============================] - 554s 429ms/step - loss: 0.0798 - acc: 0.4610 - val_loss: 0.5632 - val_acc: 0.4553\n",
      "Epoch 2/10\n",
      "1292/1292 [==============================] - 545s 421ms/step - loss: -0.2002 - acc: 0.4619 - val_loss: 0.0506 - val_acc: 0.4574\n",
      "Epoch 3/10\n",
      "1292/1292 [==============================] - 564s 437ms/step - loss: -0.0424 - acc: 0.4650 - val_loss: -0.2589 - val_acc: 0.4577\n",
      "Epoch 4/10\n",
      "1292/1292 [==============================] - 583s 451ms/step - loss: -0.2362 - acc: 0.4639 - val_loss: -0.1299 - val_acc: 0.4602\n",
      "Epoch 5/10\n",
      "1292/1292 [==============================] - 572s 443ms/step - loss: -0.8435 - acc: 0.4725 - val_loss: -1.1468 - val_acc: 0.5018\n",
      "Epoch 6/10\n",
      "1292/1292 [==============================] - 569s 440ms/step - loss: -1.1712 - acc: 0.4839 - val_loss: -1.3310 - val_acc: 0.4689\n",
      "Epoch 7/10\n",
      "1292/1292 [==============================] - 540s 418ms/step - loss: -0.8657 - acc: 0.4749 - val_loss: -1.2684 - val_acc: 0.4702\n",
      "Epoch 8/10\n",
      "1292/1292 [==============================] - 531s 411ms/step - loss: -1.3547 - acc: 0.4917 - val_loss: -0.9495 - val_acc: 0.4938\n",
      "Epoch 9/10\n",
      "1292/1292 [==============================] - 585s 453ms/step - loss: -1.4537 - acc: 0.5080 - val_loss: -1.5250 - val_acc: 0.5150\n",
      "Epoch 10/10\n",
      "1292/1292 [==============================] - 555s 429ms/step - loss: -1.4946 - acc: 0.5108 - val_loss: -1.4480 - val_acc: 0.5141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29ba122e4a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1.3393548727035522, acc: 0.5148705244064331\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1292/1292 [==============================] - 89s 69ms/step - loss: -988483.5000 - acc: 0.4483 - val_loss: -4403449.0000 - val_acc: 0.4309\n",
      "Epoch 2/5\n",
      "1292/1292 [==============================] - 87s 67ms/step - loss: -27949140.0000 - acc: 0.4437 - val_loss: -57549448.0000 - val_acc: 0.4421\n",
      "Epoch 3/5\n",
      "1292/1292 [==============================] - 87s 67ms/step - loss: -149946816.0000 - acc: 0.4436 - val_loss: -222597328.0000 - val_acc: 0.4482\n",
      "Epoch 4/5\n",
      "1292/1292 [==============================] - 95s 74ms/step - loss: -460484768.0000 - acc: 0.4442 - val_loss: -571984832.0000 - val_acc: 0.4502\n",
      "Epoch 5/5\n",
      "1292/1292 [==============================] - 105s 81ms/step - loss: -1016310080.0000 - acc: 0.4449 - val_loss: -1172016640.0000 - val_acc: 0.4497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29bb4353470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.ConvModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -1159315328.0, acc: 0.45410215854644775\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101147, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12228, 300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tw_tok = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "x = np.array((tweets['Text']).apply(lambda x: ' '.join([w for w in tw_tok.tokenize(x)])))\n",
    "\n",
    "# One-hot encoding labelu\n",
    "y = np.array(tweets['Label'].apply(lambda x: 2 if x == 'Positive' else (1 if x =='Neutral' else 0)))\n",
    "#     y = np.array(tweets['Label'].apply(lambda x: 1 if x == 'Positive' else 0))\n",
    "\n",
    "tweet_count = len(tweets)\n",
    "limit = int(0.8 * tweet_count)\n",
    "\n",
    "train_x = x[:limit]\n",
    "train_y = y[:limit]\n",
    "test_x = x[limit:]\n",
    "test_y = y[limit:]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "train_x = tokenizer.texts_to_sequences(train_x)\n",
    "test_x = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59991"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikacia do 2 tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "646/646 [==============================] - 600s 929ms/step - loss: 0.5804 - acc: 0.7224 - val_loss: 0.5911 - val_acc: 0.7197\n",
      "Epoch 2/15\n",
      "646/646 [==============================] - 584s 903ms/step - loss: 0.5721 - acc: 0.7301 - val_loss: 0.5305 - val_acc: 0.7533\n",
      "Epoch 3/15\n",
      "646/646 [==============================] - 557s 862ms/step - loss: 0.5083 - acc: 0.7679 - val_loss: 0.4926 - val_acc: 0.7774\n",
      "Epoch 4/15\n",
      "646/646 [==============================] - 613s 949ms/step - loss: 0.4787 - acc: 0.7866 - val_loss: 0.4837 - val_acc: 0.7819\n",
      "Epoch 5/15\n",
      "646/646 [==============================] - 625s 968ms/step - loss: 0.4696 - acc: 0.7918 - val_loss: 0.4764 - val_acc: 0.7853\n",
      "Epoch 6/15\n",
      "646/646 [==============================] - 608s 942ms/step - loss: 0.4605 - acc: 0.7960 - val_loss: 0.4684 - val_acc: 0.7930\n",
      "Epoch 7/15\n",
      "646/646 [==============================] - 614s 950ms/step - loss: 0.4533 - acc: 0.8008 - val_loss: 0.4660 - val_acc: 0.7937\n",
      "Epoch 8/15\n",
      "646/646 [==============================] - 621s 961ms/step - loss: 0.4467 - acc: 0.8041 - val_loss: 0.4763 - val_acc: 0.7881\n",
      "Epoch 9/15\n",
      "646/646 [==============================] - 603s 933ms/step - loss: 0.4391 - acc: 0.8074 - val_loss: 0.4649 - val_acc: 0.7956\n",
      "Epoch 10/15\n",
      "646/646 [==============================] - 608s 941ms/step - loss: 0.4309 - acc: 0.8109 - val_loss: 0.4594 - val_acc: 0.7975\n",
      "Epoch 11/15\n",
      "646/646 [==============================] - 628s 972ms/step - loss: 0.4231 - acc: 0.8155 - val_loss: 0.4666 - val_acc: 0.7975\n",
      "Epoch 12/15\n",
      "646/646 [==============================] - 611s 946ms/step - loss: 0.4126 - acc: 0.8205 - val_loss: 0.4670 - val_acc: 0.7993\n",
      "Epoch 13/15\n",
      "646/646 [==============================] - 622s 963ms/step - loss: 0.4005 - acc: 0.8262 - val_loss: 0.4699 - val_acc: 0.7945\n",
      "Epoch 14/15\n",
      "646/646 [==============================] - 625s 967ms/step - loss: 0.3874 - acc: 0.8326 - val_loss: 0.4768 - val_acc: 0.7955\n",
      "Epoch 15/15\n",
      "646/646 [==============================] - 639s 988ms/step - loss: 0.3730 - acc: 0.8408 - val_loss: 0.4788 - val_acc: 0.7904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3ed9dbf60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.49845778942108154, acc: 0.7808824777603149\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
