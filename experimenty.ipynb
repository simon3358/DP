{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models as gsm\n",
    "import phrase2vec as p2v\n",
    "from utils import create_tweet_vectors, create_emoji_tweets, create_emoji_sentiment\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacitanie dat a embeddingov\n",
    "- E2V data\n",
    "- emocontext data\n",
    "- NLP modely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('D:\\Downloads\\DP\\data\\e2v_data.csv')\n",
    "# tweets = pd.read_csv('D:\\Downloads\\DP\\data\\e2v_data_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('D:\\Downloads\\DP\\data\\emocontext.csv')\n",
    "# tweets = pd.read_csv('D:\\Downloads\\DP\\data\\emocontext_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "      <td>Don't worry  I'm girl hmm how do I know if you...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "      <td>When did I? saw many times i think -_- No. I n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "      <td>By by Google Chrome Where you live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "      <td>U r ridiculous I might be ridiculous but I am ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "      <td>Just for time pass wt do u do 4 a living then ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   first                                             second  \\\n",
       "0  Don't worry  I'm girl                       hmm how do I know if you are   \n",
       "1            When did I?                         saw many times i think -_-   \n",
       "2                     By                                   by Google Chrome   \n",
       "3         U r ridiculous  I might be ridiculous but I am telling the truth.   \n",
       "4     Just for time pass                         wt do u do 4 a living then   \n",
       "\n",
       "                       third   Label  \\\n",
       "0            What's ur name?  others   \n",
       "1        No. I never saw you   angry   \n",
       "2             Where you live  others   \n",
       "3  U little disgusting whore   angry   \n",
       "4                      Maybe  others   \n",
       "\n",
       "                                                Text  Sentiment  \n",
       "0  Don't worry  I'm girl hmm how do I know if you...        0.0  \n",
       "1  When did I? saw many times i think -_- No. I n...        0.0  \n",
       "2                 By by Google Chrome Where you live        0.0  \n",
       "3  U r ridiculous I might be ridiculous but I am ...        0.0  \n",
       "4  Just for time pass wt do u do 4 a living then ...        0.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17948 | INFO | loading projection weights from D:\\Downloads\\DP\\word2vec300_en.vec\n",
      "17948 | INFO | loaded (2000000, 300) matrix from D:\\Downloads\\DP\\word2vec300_en.vec\n"
     ]
    }
   ],
   "source": [
    "phrase_model_en = p2v.Phrase2Vec(\n",
    "    300,\n",
    "    gsm.KeyedVectors.load_word2vec_format('D:\\Downloads\\DP\\word2vec300_en.vec', binary=False),\n",
    "    gsm.KeyedVectors.load_word2vec_format('D:\\Downloads\\DP\\emoji2vec300.bin', binary=True)\n",
    ")\n",
    "\n",
    "phrase_model_no_e2v_en = p2v.Phrase2Vec(\n",
    "    300,\n",
    "    gsm.KeyedVectors.load_word2vec_format('D:\\Downloads\\DP\\word2vec300_en.vec', binary=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verzia pre slovencinu\n",
    "\n",
    "# phrase_model_sk = p2v.Phrase2Vec(\n",
    "#     300,\n",
    "#     gsm.KeyedVectors.load_word2vec_format('D:\\Downloads\\DP\\word2vec300_sk.vec', binary=False),\n",
    "#     gsm.KeyedVectors.load_word2vec_format('D:\\Downloads\\DP\\emoji2vec300.bin', binary=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vytvorenie subdatasetu s emotikonmi\n",
    "\n",
    "# create_emoji_tweets(tweets, phrase_model_en.emojiVecModel, 'D:\\Downloads\\DP\\data\\e2v_data_emoji.csv')\n",
    "# create_emoji_tweets(emocontext, phrase_model_en.emojiVecModel, 'D:\\Downloads\\DP\\data\\emocontext_emoji.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priprava dat\n",
    "- rozdelenie dat v zadanom pomere na podmnoziny, s rozdelenim labelov (predikovana hodnota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pri EMOCONTEXT su pouzite niektore nove emotikony -> nahradime\n",
    "emo_mapping = {\n",
    "    '🙂':'',\n",
    "    '🙁':'😕',\n",
    "    '🤣':'😂',\n",
    "    '🤐':'😬',\n",
    "    '🙄':'😏',\n",
    "    '🍾':'🍹',\n",
    "    '🤗':'☺',\n",
    "    '🤔':'😏',\n",
    "    '🤡':'🃏',\n",
    "    '🛰':'',\n",
    "    '🤑':'💰',\n",
    "    '\\u200d':'',\n",
    "    '🤥':'😢',\n",
    "    '🤕':'',\n",
    "    '🖕':'',\n",
    "    '🤦':'',\n",
    "    '🕺':'',\n",
    "    '🏕':'',\n",
    "    '🙃':'',\n",
    "    '🤒':'',\n",
    "    '🏣':'',\n",
    "    '🤷':'💁',\n",
    "    '🤢':'',\n",
    "    '🏖':'',\n",
    "   '🏋':'',\n",
    "    '🤘':'',\n",
    "    '🤖':'',\n",
    "    '⏸':''\n",
    "}\n",
    "\n",
    "for i, j in emo_mapping.items():\n",
    "    tweets['Text'] = tweets['Text'].str.replace(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = create_emoji_sentiment(tweets, phrase_model_en.emojiVecModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_x, train_y, valid_x, valid_y, test_x, test_y = create_tweet_vectors(tweets, phrase_model_no_e2v_en, 0.7, False)\n",
    "train_x_e2v, _, valid_x_e2v, _, test_x_e2v, _ = create_tweet_vectors(tweets, phrase_model_en, 0.7, False)\n",
    "\n",
    "train_x_sen, _, valid_x_sen, _, test_x_sen, _ = create_tweet_vectors(tweets, phrase_model_no_e2v_en, 0.7, True)\n",
    "train_x_e2v_sen, _, valid_x_e2v_sen, _, test_x_e2v_sen, _ = create_tweet_vectors(tweets, phrase_model_en, 0.7, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader - ziskanie baseline-u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Lex'] = tweets['Text'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
    "tweets['Lex_label'] = tweets['Lex'].apply(lambda x: 'Positive' if x > 0.05 else ('Neutral' if x > -0.05 else 'Negative')) \n",
    "# hranice 0.05 su dane od autora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5431198625365717"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(tweets['Label'], tweets['Lex_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5400893160942533"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(tweets['Label'], tweets['Lex_label'], average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skumanie chybovosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ():  0.6497929130234699 0.618961868646031\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "model = SVC(kernel='linear', C = 1.5)\n",
    "model.fit(train_x_e2v_sen, train_y)\n",
    "\n",
    "predict = model.predict(test_x_e2v_sen)\n",
    "acc = metrics.accuracy_score(test_y, predict)\n",
    "f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "print(\"SVM (): \", acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Lex</th>\n",
       "      <th>Lex_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10855</th>\n",
       "      <td>10855</td>\n",
       "      <td>514973201596547072</td>\n",
       "      <td>Positive</td>\n",
       "      <td>@JennaSeychel pls bring my backpack I need it ...</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10856</th>\n",
       "      <td>10856</td>\n",
       "      <td>514617822430134272</td>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @michelleswid: life is good 😊😊😊😊</td>\n",
       "      <td>1.935</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10857</th>\n",
       "      <td>10857</td>\n",
       "      <td>511602407265284097</td>\n",
       "      <td>Negative</td>\n",
       "      <td>And I like it that way gives me less time to t...</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>10858</td>\n",
       "      <td>511666785636986880</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Love And Hip Hop Hollwood 🙌🙌 Some Cold Chicks ...</td>\n",
       "      <td>1.852</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>10859</td>\n",
       "      <td>513299447833690112</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @_zach5: “@MrExposed: \"Female Intuition\" ht...</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>10860</td>\n",
       "      <td>514575489306882048</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My dream job is to work at FedEx 😂</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>10861</td>\n",
       "      <td>513283400439181312</td>\n",
       "      <td>Positive</td>\n",
       "      <td>When @Shauski asks me to take a photo of him w...</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>10862</td>\n",
       "      <td>513082170295201792</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@TiaSoSolid @MadiMego 😂😩 you threw that shit up!</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.4753</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10863</th>\n",
       "      <td>10863</td>\n",
       "      <td>514262405506146304</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The Stupid Things I Do 🙈 I Do It For You 😩😘😍</td>\n",
       "      <td>1.445</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>10864</td>\n",
       "      <td>514914422629101569</td>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @SamiraIbrahimx: @MissKhynatNisa I'm CRYJNG...</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  Id     Label  \\\n",
       "10855       10855  514973201596547072  Positive   \n",
       "10856       10856  514617822430134272  Positive   \n",
       "10857       10857  511602407265284097  Negative   \n",
       "10858       10858  511666785636986880   Neutral   \n",
       "10859       10859  513299447833690112   Neutral   \n",
       "10860       10860  514575489306882048  Positive   \n",
       "10861       10861  513283400439181312  Positive   \n",
       "10862       10862  513082170295201792  Negative   \n",
       "10863       10863  514262405506146304  Negative   \n",
       "10864       10864  514914422629101569  Positive   \n",
       "\n",
       "                                                    Text  Sentiment     Lex  \\\n",
       "10855  @JennaSeychel pls bring my backpack I need it ...      0.221  0.4404   \n",
       "10856                RT @michelleswid: life is good 😊😊😊😊      1.935  0.9774   \n",
       "10857  And I like it that way gives me less time to t...      0.664  0.3612   \n",
       "10858  Love And Hip Hop Hollwood 🙌🙌 Some Cold Chicks ...      1.852  0.8807   \n",
       "10859  RT @_zach5: “@MrExposed: \"Female Intuition\" ht...      0.663  0.8271   \n",
       "10860                 My dream job is to work at FedEx 😂      0.221  0.5994   \n",
       "10861  When @Shauski asks me to take a photo of him w...      0.630  0.6705   \n",
       "10862   @TiaSoSolid @MadiMego 😂😩 you threw that shit up!     -0.147 -0.4753   \n",
       "10863       The Stupid Things I Do 🙈 I Do It For You 😩😘😍      1.445  0.0772   \n",
       "10864  RT @SamiraIbrahimx: @MissKhynatNisa I'm CRYJNG...      1.326  0.9378   \n",
       "\n",
       "      Lex_label  \n",
       "10855  Positive  \n",
       "10856  Positive  \n",
       "10857  Positive  \n",
       "10858  Positive  \n",
       "10859  Positive  \n",
       "10860  Positive  \n",
       "10861  Positive  \n",
       "10862  Negative  \n",
       "10863  Positive  \n",
       "10864  Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction from SVM\n",
    "predict[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df  = tweets[-len(predict_df):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(data=predict,columns=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat([compare_df, predict_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_different = compare_df[compare_df['Label']!=compare_df['Pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2173"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_different.to_csv('D:\\Downloads\\DP\\data\\compare_results.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcie (NB, RF, GBT)\n",
    "- overenie uspesnosti modelov:\n",
    "    - model (w2v)\n",
    "    - model (w2v, e2v) \n",
    "    - model (w2v, senti)\n",
    "    - model (w2v, e2v, senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_classic(model, train_x, train_y, test_x, test_y, text):\n",
    "    model.fit(train_x, train_y)\n",
    "    predict = model.predict(test_x)\n",
    "    acc = metrics.accuracy_score(test_y, predict)\n",
    "    f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "    print(text, \":   acc: \", acc,\" F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(model, params, train_x, train_y, valid_x, valid_y, test_x, test_y, text):\n",
    "    rand_optim = RandomizedSearchCV(model, param_distributions=params, \n",
    "                                          cv=5, random_state=42, n_jobs=-1, n_iter = 30, scoring='f1_weighted')\n",
    "    rand_optim.fit(valid_x, valid_y)\n",
    "    cls = rand_optim.best_estimator_\n",
    "    cls.fit(train_x, train_y)\n",
    "    predict = cls.predict(test_x)\n",
    "    acc = metrics.accuracy_score(test_y, predict)\n",
    "    f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "    print(text, \": acc: \", acc,\" F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB(.......) :   acc:  0.40384615384615385  F1:  0.4148528449998235\n",
      "NB(e2v....) :   acc:  0.40340406719717065  F1:  0.41230589749011687\n",
      "NB(sen....) :   acc:  0.40738284703801947  F1:  0.41638254147705095\n",
      "NB(e2v+sen) :   acc:  0.40893015030946067  F1:  0.41760145118807346\n"
     ]
    }
   ],
   "source": [
    "experiment_classic(GaussianNB(), train_x, train_y, test_x, test_y, \"NB(.......)\")\n",
    "experiment_classic(GaussianNB(), train_x_e2v, train_y, test_x_e2v, test_y, \"NB(e2v....)\")\n",
    "experiment_classic(GaussianNB(), train_x_sen, train_y, test_x_sen, test_y, \"NB(sen....)\")\n",
    "experiment_classic(GaussianNB(), train_x_e2v_sen, train_y, test_x_e2v_sen, test_y, \"NB(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(.......) : acc:  0.580238726790451  F1:  0.5237994581107316\n",
      "RF(e2v....) : acc:  0.5904067197170646  F1:  0.5355462551074105\n",
      "RF(sen....) : acc:  0.600132625994695  F1:  0.5461245555800168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(e2v+sen) : acc:  0.6069849690539346  F1:  0.5515246932090708\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(1,15),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': stats.randint(1,4),\n",
    "    'min_samples_split': stats.randint(2,5),\n",
    "    'n_estimators': [20,60,100,150]\n",
    "}\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"RF(.......)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"RF(e2v....)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"RF(sen....)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"RF(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT(.......) : acc:  0.6602564102564102  F1:  0.6440337488465383\n",
      "GBT(e2v....) : acc:  0.6927497789566756  F1:  0.6838635656952176\n",
      "GBT(sen....) : acc:  0.6799292661361627  F1:  0.6694423832323089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT(e2v+sen) : acc:  0.7013704686118479  F1:  0.6944036553872569\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(1,15),\n",
    "    'learning_rate': [0.1,0.125,0.15,0.175,0.2,0.225,0.25],\n",
    "    'min_samples_leaf': stats.randint(1,5),\n",
    "    'min_samples_split' : stats.randint(2,10),\n",
    "    'n_estimators' : [20,60,100,150]\n",
    "}\n",
    "experiment(GradientBoostingClassifier(), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"GBT(.......)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"GBT(e2v....)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"GBT(sen....)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"GBT(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(.......) : acc:  0.7031388152077808  F1:  0.6908288914366676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(e2v....) : acc:  0.7155172413793104  F1:  0.7052029118913062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(sen....) : acc:  0.7066755083996463  F1:  0.6962512386082086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(e2v+sen) : acc:  0.7172855879752431  F1:  0.7077415400476647\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid','linear'],\n",
    "    'C': [1,1.25,1.5,1.75,2]\n",
    "}\n",
    "experiment(SVC(), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"SVM(.......)\")\n",
    "experiment(SVC(), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"SVM(e2v....)\")\n",
    "experiment(SVC(), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"SVM(sen....)\")\n",
    "experiment(SVC(), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"SVM(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcie (NB, RF, GBT, SVM) - ONLY EMOJI\n",
    "- overenie uspesnosti modelov:\n",
    "    - model (w2v)\n",
    "    - model (w2v, e2v) \n",
    "    - model (w2v, senti)\n",
    "    - model (w2v, e2v, senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB(.......) :   acc:  0.3905579399141631  F1:  0.35613741526254494\n",
      "NB(e2v....) :   acc:  0.4034334763948498  F1:  0.3749824058998293\n",
      "NB(sen....) :   acc:  0.4083384426732066  F1:  0.3797264388217386\n",
      "NB(e2v+sen) :   acc:  0.42427958307786634  F1:  0.40238083174135625\n"
     ]
    }
   ],
   "source": [
    "experiment_classic(GaussianNB(), train_x, train_y, test_x, test_y, \"NB(.......)\")\n",
    "experiment_classic(GaussianNB(), train_x_e2v, train_y, test_x_e2v, test_y, \"NB(e2v....)\")\n",
    "experiment_classic(GaussianNB(), train_x_sen, train_y, test_x_sen, test_y, \"NB(sen....)\")\n",
    "experiment_classic(GaussianNB(), train_x_e2v_sen, train_y, test_x_e2v_sen, test_y, \"NB(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(.......) : acc:  0.5548743102391172  F1:  0.5114888577276904\n",
      "RF(e2v....) : acc:  0.5824647455548743  F1:  0.534839547416412\n",
      "RF(sen....) : acc:  0.645003065603924  F1:  0.5964671151773155\n",
      "RF(e2v+sen) : acc:  0.6443899448191294  F1:  0.5974335224381752\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(1,15),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': stats.randint(1,4),\n",
    "    'min_samples_split': stats.randint(2,5),\n",
    "    'n_estimators': [20,60,100,150]\n",
    "}\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"RF(.......)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"RF(e2v....)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"RF(sen....)\")\n",
    "experiment(RandomForestClassifier(random_state=0), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"RF(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT(.......) : acc:  0.5757204169221337  F1:  0.5637526421096641\n",
      "GBT(e2v....) : acc:  0.5947271612507664  F1:  0.5840173928497374\n",
      "GBT(sen....) : acc:  0.6456161863887185  F1:  0.6301589259138404\n",
      "GBT(e2v+sen) : acc:  0.6394849785407726  F1:  0.6233259728668625\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(1,15),\n",
    "    'learning_rate': [0.1,0.125,0.15,0.175,0.2,0.225,0.25],\n",
    "    'min_samples_leaf': stats.randint(1,5),\n",
    "    'min_samples_split' : stats.randint(2,10),\n",
    "    'n_estimators' : [20,60,100,150]\n",
    "}\n",
    "experiment(GradientBoostingClassifier(), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"GBT(.......)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"GBT(e2v....)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"GBT(sen....)\")\n",
    "experiment(GradientBoostingClassifier(), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"GBT(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(.......) : acc:  0.595340282035561  F1:  0.5570387671764473\n",
      "SVM(e2v....) : acc:  0.6413243408951563  F1:  0.6101881788247093\n",
      "SVM(sen....) : acc:  0.6603310852237891  F1:  0.6261564448749984\n",
      "SVM(e2v+sen) : acc:  0.65113427345187  F1:  0.6218271188087804\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid','linear'],\n",
    "    'C': [1,1.25,1.5,1.75,2]\n",
    "}\n",
    "experiment(SVC(), params, train_x, train_y, valid_x, valid_y, test_x, test_y, \"SVM(.......)\")\n",
    "experiment(SVC(), params, train_x_e2v, train_y, valid_x_e2v, valid_y, test_x_e2v, test_y, \"SVM(e2v....)\")\n",
    "experiment(SVC(), params, train_x_sen, train_y, valid_x_sen, valid_y, test_x_sen, test_y, \"SVM(sen....)\")\n",
    "experiment(SVC(), params, train_x_e2v_sen, train_y, valid_x_e2v_sen, valid_y, test_x_e2v_sen, test_y, \"SVM(e2v+sen)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoostTree ():  0.5789473684210527 0.5676951080390289\n"
     ]
    }
   ],
   "source": [
    "# grad. boosting trees\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "predict = model.predict(test_x)\n",
    "acc = metrics.accuracy_score(test_y, predict)\n",
    "f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "print(\"GradBoostTree (): \", acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676951080390289"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_y, predict, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_y, predict, average='micro')\n",
    "# na stackoverflowe je pekne vysvetlene kedy a preco je to rovnake ako ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ():  0.6497929130234699 0.618961868646031\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "model = SVC(kernel='linear', C = 1.5)\n",
    "model.fit(train_x_e2v_sen, train_y)\n",
    "\n",
    "predict = model.predict(test_x_e2v_sen)\n",
    "acc = metrics.accuracy_score(test_y, predict)\n",
    "f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "print(\"SVM (): \", acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:  0.519558214450069 0.4884329060108204\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "model = RandomForestClassifier(n_estimators=60)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "predict = model.predict(test_x)\n",
    "acc = metrics.accuracy_score(test_y, predict)\n",
    "f1 = metrics.f1_score(test_y, predict, average='weighted')\n",
    "print(\"RandomForest: \", acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "score = model_selection.cross_val_score(RandomForestClassifier(n_estimators=60), train_x, train_y, cv=5)\n",
    "print(score.mean(), score.std()*2)\n",
    "score = model_selection.cross_val_score(RandomForestClassifier(n_estimators=60), train_x_e2v, train_y, cv=5)\n",
    "print(score.mean(), score.std()*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = int(len(train_x)*0.8)\n",
    "valid_x = train_x[limit:]\n",
    "train_x = train_x[:limit]\n",
    "valid_y = train_y[limit:]\n",
    "train_y = train_y[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RandomForest---\n",
      "Accuracy:  0.5773219814241486\n",
      "0.557900552605684\n",
      "\n",
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
      "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(1,15),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': stats.randint(1,4),\n",
    "    'min_samples_split': stats.randint(2,5),\n",
    "    'n_estimators': [20,60,100,150]\n",
    "}\n",
    "\n",
    "random_optimization = RandomizedSearchCV(RandomForestClassifier(random_state=0), param_distributions=params, \n",
    "                                          cv=5, random_state=42, n_jobs=-1, n_iter = 30, scoring='f1_weighted')\n",
    "\n",
    "random_optimization.fit(valid_x, valid_y)\n",
    "\n",
    "\n",
    "# RandomForest\n",
    "cls = random_optimization.best_estimator_\n",
    "cls.fit(train_x, train_y)\n",
    "\n",
    "print(\"---RandomForest---\")         \n",
    "predict = cls.predict(test_x)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(predict, test_y))\n",
    "print(metrics.f1_score(test_y, predict, average='weighted'))\n",
    "print()\n",
    "print(cls.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
