{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import encode_data_get_embeddings, create_emoji_sentiment\n",
    "import model as models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacitanie dat a embedingov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DATA-EN-TW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data.csv')\n",
    "tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data_emoji.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DATA-EN-SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = pd.read_csv('D:\\Downloads\\DP\\data\\emocontext.csv')\n",
    "tweets = pd.read_csv('D:\\Downloads\\DP\\data\\emocontext_emoji.csv')\n",
    "\n",
    "# tweets_train = pd.read_csv('D:/Downloads/DP/data/emocontext.csv')\n",
    "# tweets_dev = pd.read_csv('D:/Downloads/DP/data/emocontext_dev.csv')\n",
    "# tweets_test = pd.read_csv('D:/Downloads/DP/data/emocontext_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DATA-SK-FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = pd.read_csv('D:/Downloads/DP/data/seesame.csv')\n",
    "tweets = pd.read_csv('D:/Downloads/DP/data/seesame_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000 300\n",
      "\n",
      "1661 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v = open('D:\\Downloads\\DP\\word2vec300_en.vec', encoding=\"utf8\")\n",
    "w2v_dim = w2v.readline()\n",
    "print(w2v_dim)\n",
    "\n",
    "e2v = open('D:\\Downloads\\DP\\emoji2vec300.txt', encoding=\"utf8\")\n",
    "e2v_dim = e2v.readline()\n",
    "print(e2v_dim)\n",
    "\n",
    "train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, None)\n",
    "# train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, tw_cnt, w2v, e2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcie - Neuronove siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLstm - DATA-EN-SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['others', 'sad', 'happy', 'angry']\n",
    "predict = model.predict(test_x)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "predict = [classes[pr] for pr in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(embedding_matrix.shape[0],\n",
    "                 300,\n",
    "                 weights=[embedding_matrix],\n",
    "                 input_length=80,\n",
    "                 trainable=False))\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=256,\n",
    "            dropout=0.1,\n",
    "            recurrent_dropout=0.1\n",
    "                            )))\n",
    "\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, \n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(tweets.Label[tw_cnt:], predict, average='micro', labels=['sad', 'happy', 'angry']))\n",
    "print(classification_report(tweets.Label[tw_cnt:], predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLstm - DATA-EN-TW / DATA-SK-FB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('D:/Downloads/DP/data/e2v_data_emoji.csv')\n",
    "\n",
    "w2v = open('D:\\Downloads\\DP\\word2vec300_en.vec', encoding=\"utf8\")\n",
    "w2v_dim = w2v.readline()\n",
    "print(w2v_dim)\n",
    "\n",
    "e2v = open('D:\\Downloads\\DP\\emoji2vec300.txt', encoding=\"utf8\")\n",
    "e2v_dim = e2v.readline()\n",
    "print(e2v_dim)\n",
    "\n",
    "train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, None)\n",
    "# train_x, train_y, test_x, test_y, embedding_matrix = encode_data_get_embeddings(tweets, 0.8, w2v, e2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "302/302 [==============================] - 117s 389ms/step - loss: 0.8910 - acc: 0.6539 - val_loss: 0.6864 - val_acc: 0.7261\n",
      "Epoch 2/10\n",
      "302/302 [==============================] - 104s 343ms/step - loss: 0.5986 - acc: 0.7704 - val_loss: 0.5821 - val_acc: 0.7793\n",
      "Epoch 3/10\n",
      "302/302 [==============================] - 105s 348ms/step - loss: 0.5073 - acc: 0.8099 - val_loss: 0.5337 - val_acc: 0.7984\n",
      "Epoch 4/10\n",
      "302/302 [==============================] - 105s 348ms/step - loss: 0.4685 - acc: 0.8220 - val_loss: 0.5300 - val_acc: 0.8040\n",
      "Epoch 5/10\n",
      "302/302 [==============================] - 105s 349ms/step - loss: 0.4275 - acc: 0.8405 - val_loss: 0.4784 - val_acc: 0.8257\n",
      "Epoch 6/10\n",
      "302/302 [==============================] - 106s 350ms/step - loss: 0.3968 - acc: 0.8557 - val_loss: 0.4467 - val_acc: 0.8361\n",
      "Epoch 7/10\n",
      "302/302 [==============================] - 106s 350ms/step - loss: 0.3733 - acc: 0.8645 - val_loss: 0.4531 - val_acc: 0.8373\n",
      "Epoch 8/10\n",
      "302/302 [==============================] - 106s 350ms/step - loss: 0.3477 - acc: 0.8734 - val_loss: 0.4665 - val_acc: 0.8272\n",
      "Epoch 9/10\n",
      "302/302 [==============================] - 106s 351ms/step - loss: 0.3281 - acc: 0.8802 - val_loss: 0.4355 - val_acc: 0.8458\n",
      "Epoch 10/10\n",
      "302/302 [==============================] - 106s 352ms/step - loss: 0.3099 - acc: 0.8880 - val_loss: 0.4408 - val_acc: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2840e895f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.430917888879776, acc: 0.8461538553237915\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.TestModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.BiLstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.ConvModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.BaselineModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselineDrop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.BaselineDropModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LstmModel(embedding_matrix)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['acc'])  \n",
    "\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f'loss: {score[0]}, acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101147, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12228, 300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tw_tok = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "x = np.array((tweets['Text']).apply(lambda x: ' '.join([w for w in tw_tok.tokenize(x)])))\n",
    "\n",
    "# One-hot encoding labelu\n",
    "y = np.array(tweets['Label'].apply(lambda x: 2 if x == 'Positive' else (1 if x =='Neutral' else 0)))\n",
    "#     y = np.array(tweets['Label'].apply(lambda x: 1 if x == 'Positive' else 0))\n",
    "\n",
    "tweet_count = len(tweets)\n",
    "limit = int(0.8 * tweet_count)\n",
    "\n",
    "train_x = x[:limit]\n",
    "train_y = y[:limit]\n",
    "test_x = x[limit:]\n",
    "test_y = y[limit:]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "train_x = tokenizer.texts_to_sequences(train_x)\n",
    "test_x = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59991"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
